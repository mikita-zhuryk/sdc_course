{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3: Perception\n",
    "\n",
    "В этом задании вам будет необходимо обучить PointNet для задачи фильтрации шума в лидарном облаке.\n",
    "\n",
    "В 3 семинаре мы с вами придумавали руками фичи и пытались обучить на этих данных catboost. Практика показывает, что сетки куда более способные генераторы фичей.\n",
    "\n",
    "[Данные](https://yadi.sk/d/CBoVCVIxJ2q2cw)\n",
    "\n",
    "Задание:\n",
    "\n",
    "1. Необходимо реализовать PointNet, который будет работать на данных со снегом из 3 семинара. PointNet должен работать на окрестностях точек, нет смысла запускать его на всем облаке. PointNet должен включать в себя шаг агрегации по множеству: например с помощью функции максимума, шаг подклеивания агрегированного вектора к исходным точкам и шаг вычисления фичей по отдельным точкам. Вероятно вы захотите повторить эту процедуру несколько раз для улучшения качества. Статья: https://arxiv.org/abs/1612.00593. Вы можете выбрать любой фреймворк для реализации.\n",
    "2. Ваш PointNet должен ограничить сверху размер окрестности. В референсной реализации использовались 64 точки.\n",
    "3. Разбиение на train/test. Для разбиения используйте следующий код.\n",
    "```\n",
    "scene_indices = np.arange(0, 291)\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(scene_indices)\n",
    "train_indices = scene_indices[:260]\n",
    "test_indices = scene_indices[260:]\n",
    "```\n",
    "4. Данные лучше генерировать on-demand, таким образом вам не придется хранить в памяти большие массивы точек. В tensorflow это можно реализовать через tf.data.\n",
    "\n",
    "5. PointNet это функция, которая работает на неупорядоченном множестве точек. В нашем же кейсе мы не хотим предсказать свойство окрестности, мы хотим предсказать свойство точки. Подумайте о том как можно модифицировать архитектуру, чтобы pointnet \"не забывал\" фичи точки, которая нам интересна. (Это поможет улучшить качество)\n",
    "\n",
    "\n",
    "## Формальные требования\n",
    "\n",
    "1. В вашей архитектуре должны быть признаки PointNet: вычисление глобального вектора множества, подклеивание его обратно, вычисление фичей по точкам.\n",
    "\n",
    "2. ROC-AUC на тестовом датасете должен превышать 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import typing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikita-zhuryk/shad/shad-sdc/env/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('data/snow_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>intensity</th>\n",
       "      <th>ring</th>\n",
       "      <th>label</th>\n",
       "      <th>min_intensity_1.0</th>\n",
       "      <th>max_intensity_1.0</th>\n",
       "      <th>median_intensity_1.0</th>\n",
       "      <th>std_intensity_1.0</th>\n",
       "      <th>min_ring_1.0</th>\n",
       "      <th>max_ring_1.0</th>\n",
       "      <th>median_ring_1.0</th>\n",
       "      <th>std_ring_1.0</th>\n",
       "      <th>r_std_1.0</th>\n",
       "      <th>n_neighbours_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.355618</td>\n",
       "      <td>-4.206962</td>\n",
       "      <td>0.344085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.916535</td>\n",
       "      <td>-1.972164</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.410451</td>\n",
       "      <td>-2.113039</td>\n",
       "      <td>2.137792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.845870</td>\n",
       "      <td>-1.406652</td>\n",
       "      <td>0.406310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.326218</td>\n",
       "      <td>-0.346060</td>\n",
       "      <td>0.226469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-29.016968</td>\n",
       "      <td>-2.179385</td>\n",
       "      <td>0.945424</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.074985</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.044024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.730534</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.966555</td>\n",
       "      <td>0.192132</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.041912</td>\n",
       "      <td>-0.009894</td>\n",
       "      <td>0.055311</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.730534</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.966555</td>\n",
       "      <td>0.189939</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.275961</td>\n",
       "      <td>0.790447</td>\n",
       "      <td>0.086301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.041361</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.290426</td>\n",
       "      <td>1.923754</td>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scene_id          x         y         z  intensity  ring  label  \\\n",
       "0       0.0 -11.355618 -4.206962  0.344085        0.0  23.0    1.0   \n",
       "1       0.0  -5.916535 -1.972164  0.283262        0.0  25.0    1.0   \n",
       "2       0.0  -7.410451 -2.113039  2.137792        0.0  31.0    1.0   \n",
       "3       0.0 -13.845870 -1.406652  0.406310        0.0  23.0    1.0   \n",
       "4       0.0  -8.326218 -0.346060  0.226469        0.0  22.0    1.0   \n",
       "5       0.0 -29.016968 -2.179385  0.945424        7.0  24.0    1.0   \n",
       "6       0.0  -2.074985  0.003017  0.044024        2.0  16.0    1.0   \n",
       "7       0.0  -2.041912 -0.009894  0.055311        3.0  17.0    1.0   \n",
       "8       0.0  -6.275961  0.790447  0.086301        0.0  19.0    1.0   \n",
       "9       0.0  -8.290426  1.923754  0.044705        0.0  18.0    1.0   \n",
       "\n",
       "   min_intensity_1.0  max_intensity_1.0  median_intensity_1.0  \\\n",
       "0                0.0                0.0                   0.0   \n",
       "1                0.0                0.0                   0.0   \n",
       "2                0.0                0.0                   0.0   \n",
       "3                0.0                0.0                   0.0   \n",
       "4                0.0                0.0                   0.0   \n",
       "5                7.0                7.0                   7.0   \n",
       "6                2.0               21.0                   3.0   \n",
       "7                2.0               21.0                   3.0   \n",
       "8                0.0                0.0                   0.0   \n",
       "9                0.0                0.0                   0.0   \n",
       "\n",
       "   std_intensity_1.0  min_ring_1.0  max_ring_1.0  median_ring_1.0  \\\n",
       "0           0.000000          23.0          23.0             23.0   \n",
       "1           0.000000          25.0          25.0             25.0   \n",
       "2           0.000000          31.0          31.0             31.0   \n",
       "3           0.000000          23.0          23.0             23.0   \n",
       "4           0.000000          22.0          22.0             22.0   \n",
       "5           0.000000          24.0          24.0             24.0   \n",
       "6           8.730534          16.0          27.0             17.0   \n",
       "7           8.730534          16.0          27.0             17.0   \n",
       "8           0.000000          19.0          25.0             22.0   \n",
       "9           0.000000          18.0          23.0             20.5   \n",
       "\n",
       "   std_ring_1.0  r_std_1.0  n_neighbours_1.0  \n",
       "0      0.000000   0.000000               1.0  \n",
       "1      0.000000   0.000000               1.0  \n",
       "2      0.000000   0.000000               1.0  \n",
       "3      0.000000   0.000000               1.0  \n",
       "4      0.000000   0.000000               1.0  \n",
       "5      0.000000   0.000000               1.0  \n",
       "6      4.966555   0.192132               3.0  \n",
       "7      4.966555   0.189939               3.0  \n",
       "8      3.000000   0.041361               2.0  \n",
       "9      2.500000   0.028832               2.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame) -> None:\n",
    "        self.df: pd.DataFrame = data_df.reset_index(drop=True)\n",
    "        self.scene_ids = self.df.scene_id.unique().tolist()\n",
    "        self.n_scenes = len(self.scene_ids)\n",
    "        \n",
    "    def __getitem__(self, scene_idx: int) -> tp.Any:\n",
    "        return self.df[self.df.scene_id == self.scene_ids[scene_idx]]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.n_scenes\n",
    "    \n",
    "    \n",
    "class SceneDataset(Dataset):\n",
    "    def __init__(self, cloud_df: pd.DataFrame) -> None:\n",
    "        self.df: pd.DataFrame = cloud_df.reset_index(drop=True)\n",
    "        self.tree = KDTree(self.df[['x', 'y', 'z']].to_numpy())\n",
    "        self.labels = self.df.label\n",
    "        self.features = self.df.drop(columns=['label', 'scene_id'])\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> tp.Any:\n",
    "        point = self.features.iloc[idx, :3].to_numpy()\n",
    "        neighbor_ids, _ = self.tree.query_radius(point[np.newaxis, ...], r=1,\n",
    "                                                 return_distance=True, sort_results=True)\n",
    "        neighbor_ids = neighbor_ids[0]\n",
    "        return self.features.iloc[neighbor_ids].to_numpy(), self.labels.iloc[idx]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_indices = np.arange(0, 291)\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(scene_indices)\n",
    "train_indices = scene_indices[:260]\n",
    "test_indices = scene_indices[260:]\n",
    "\n",
    "train_data = features[features.scene_id.isin(train_indices)]\n",
    "test_data = features[features.scene_id.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PointCloudDataset(train_data)\n",
    "test_data = PointCloudDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics as M\n",
    "\n",
    "NAME_TO_METRIC = {'accuracy': M.accuracy_score,\n",
    "                  'recall': M.recall_score,\n",
    "                  'precision': M.precision_score,\n",
    "                  'f1': M.f1_score,\n",
    "                  'roc_auc': M.roc_auc_score}\n",
    "\n",
    "\n",
    "class ClassificationMetricLogger:\n",
    "    def __init__(self, n_classes: int, metrics: tp.List[str] = ['precision', 'recall', 'f1']) -> None:\n",
    "        self.n_metrics = len(metrics)\n",
    "        self.metrics = metrics\n",
    "        self.train_losses: tp.List[float] = []\n",
    "        self.train_preds: tp.List[int] = []\n",
    "        self.train_gt: tp.List[int] = []\n",
    "        self.val_losses: tp.List[float] = []\n",
    "        self.val_preds: tp.List[int] = []\n",
    "        self.val_gt: tp.List[int] = []\n",
    "        self._train = True\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def train(self, train: bool = True) -> None:\n",
    "        self._train = train\n",
    "\n",
    "    def eval(self) -> None:\n",
    "        self._train = False\n",
    "\n",
    "    def __logits_to_classes(self, logits: torch.Tensor) -> tp.List[int]:\n",
    "        return tp.cast(tp.List[int], torch.argmax(logits, dim=1).numpy().astype(int).tolist())\n",
    "\n",
    "    def process_predictions(self, preds: torch.Tensor, gt: torch.Tensor, loss: float) -> None:\n",
    "        classes = self.__logits_to_classes(preds)\n",
    "        gt = gt.numpy().tolist()\n",
    "        if self._train:\n",
    "            self.train_losses.append(loss)\n",
    "            self.train_preds.extend(classes)\n",
    "            self.train_gt.extend(gt)\n",
    "        else:\n",
    "            self.val_losses.append(loss)\n",
    "            self.val_preds.extend(classes)\n",
    "            self.val_gt.extend(gt)\n",
    "\n",
    "    def __metrics(self, train: bool = False) -> tp.Dict[str, float]:\n",
    "        if train:\n",
    "            losses = self.train_losses\n",
    "            preds = self.train_preds\n",
    "            gt = self.train_gt\n",
    "        else:\n",
    "            losses = self.val_losses\n",
    "            preds = self.val_preds\n",
    "            gt = self.val_gt\n",
    "\n",
    "        metric_dict = {'mean_loss': float(np.mean(losses))}\n",
    "        for metric in self.metrics:\n",
    "            metric_dict[metric] = float(NAME_TO_METRIC[metric](gt, preds,\n",
    "                                                               labels=np.arange(self.n_classes),\n",
    "                                                               average=\"weighted\"))\n",
    "        return metric_dict\n",
    "\n",
    "    def __describe_split(self, train: bool = True) -> str:\n",
    "        m = self.__metrics(train)\n",
    "        s = ''\n",
    "        for (k, v) in m.items():\n",
    "            s += f'{k}: {v}\\n'\n",
    "        return s\n",
    "\n",
    "    def train_metrics(self) -> tp.Dict[str, float]:\n",
    "        return self.__metrics(train=True)\n",
    "\n",
    "    def val_metrics(self) -> tp.Dict[str, float]:\n",
    "        return self.__metrics(train=False)\n",
    "\n",
    "    def get_summary(self) -> str:\n",
    "        s = 'Train metrics:\\n'\n",
    "        s += self.__describe_split(train=True)\n",
    "        s += 'Val metrics:\\n'\n",
    "        s += self.__describe_split(train=False)\n",
    "        return s\n",
    "\n",
    "    def print_summary(self) -> None:\n",
    "        print(self.get_summary())\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.train_losses = []\n",
    "        self.train_preds = []\n",
    "        self.train_gt = []\n",
    "        self.val_losses = []\n",
    "        self.val_preds = []\n",
    "        self.val_gt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "N_EPOCHS = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_loss(pred: torch.Tensor, gt: torch.Tensor) -> torch.Tensor:\n",
    "#     return torch.nn.functional.binary_cross_entropy_with_logits(pred, gt)\n",
    "\n",
    "compute_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def single_epoch(model: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Adam,\n",
    "                 train_data: PointCloudDataset,\n",
    "                 test_data: PointCloudDataset,\n",
    "                 compute_loss: tp.Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "                 metric_logger: ClassificationMetricLogger) -> None:\n",
    "    model.train()\n",
    "    metric_logger.train()\n",
    "    for scene_df in tqdm(train_data, desc='Train scenes'):\n",
    "        scene_data = SceneDataset(scene_df)\n",
    "        scene_loader = DataLoader(scene_data, batch_size=1, num_workers=1, shuffle=True)\n",
    "        for (features, gt) in scene_loader:\n",
    "            features = features.float()\n",
    "            gt = gt.long()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(features.to(DEVICE))\n",
    "            print(pred.shape, gt.shape)\n",
    "            loss = compute_loss(pred, gt.to(DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            metric_logger.process_predictions(pred.detach().cpu(), gt, loss.detach().cpu().item())\n",
    "            \n",
    "    model.eval()\n",
    "    metric_logger.eval()\n",
    "    with torch.no_grad():\n",
    "        for scene_df in tqdm(test_data, desc='Test scenes'):\n",
    "            scene_data = SceneDataset(scene_df)\n",
    "            scene_loader = DataLoader(scene_data, batch_size=1, num_workers=1, shuffle=True)\n",
    "            for (features, gt) in scene_loader:\n",
    "                features = features.float()\n",
    "                gt = gt.long()\n",
    "                pred = model(features.to(DEVICE))\n",
    "                loss = compute_loss(pred, gt.to(DEVICE))\n",
    "                metric_logger.process_predictions(pred.cpu(), gt, loss.cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PointNetModel(nn.Module):\n",
    "    def __init__(self, in_features: int = 15, n_out_classes: int = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(in_features, 64),\n",
    "                                 nn.Linear(64, 64))\n",
    "        self.embedding_mlp = nn.Sequential(nn.Linear(64, 128),\n",
    "                                           nn.Linear(128, 1024))\n",
    "        clf_mlp_features = 64 + 1024\n",
    "        get_clf_mlp = lambda: nn.Linear(clf_mlp_features, 1024)\n",
    "        self.combining_mlps = torch.nn.ModuleList([get_clf_mlp() for _ in range(3)])\n",
    "        self.clf_mlp = nn.Sequential(nn.Linear(clf_mlp_features + in_features, 512),\n",
    "                                     nn.Linear(512, 128),\n",
    "                                     nn.Linear(128, n_out_classes))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        x64 = self.mlp(x)\n",
    "        global_features = torch.max(self.embedding_mlp(x64), dim=1).values.view(1, 1, -1)\n",
    "        x = torch.cat((x64, torch.tile(global_features, (1, inputs.shape[1], 1))), dim=2)\n",
    "        for i in range(len(self.combining_mlps)):\n",
    "            global_features = torch.max(self.combining_mlps[i](x), dim=1).values.view(1, 1, -1)\n",
    "            x = torch.cat((x64, torch.tile(global_features, (1, inputs.shape[1], 1))), dim=2)\n",
    "        x = torch.cat((inputs, x), dim=2)\n",
    "        prediction = self.clf_mlp(x)[:, 0]\n",
    "        return torch.squeeze(prediction, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointNetModel()\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9)\n",
    "metric_logger = ClassificationMetricLogger(n_classes=2,\n",
    "                                           metrics=['precision', 'recall', 'f1', 'roc_auc'])\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ONL9sI2e_HG7pQ9zYVM-JSVqzsR_8Pnn' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ONL9sI2e_HG7pQ9zYVM-JSVqzsR_8Pnn\" -O pointnet-4.pth && rm -rf /tmp/cookies.txt\n",
    "\n",
    "# state_dict = torch.load('pointnet-4.pth', map_location='cpu')\n",
    "# model.cpu()\n",
    "# model.load_state_dict(state_dict['model'])\n",
    "# model.to(DEVICE)\n",
    "# optimizer.load_state_dict(state_dict['optimizer'])\n",
    "# scheduler.load_state_dict(state_dict['scheduler'])\n",
    "# start_epoch = state_dict['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for ep in tqdm(range(start_epoch, N_EPOCHS), desc='Epoch'):\n",
    "    single_epoch(model, optimizer, train_data, test_data, compute_loss, metric_logger)\n",
    "    print(f'Epoch {ep}:')\n",
    "    metric_logger.print_summary()\n",
    "    scheduler.step()\n",
    "    state_dict = {'model': model.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict(),\n",
    "                  'scheduler': scheduler.state_dict(),\n",
    "                  'epoch': ep}\n",
    "    torch.save(state_dict, f'pointnet-{ep}.pth')\n",
    "    metric_logger.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shad-sdc)",
   "language": "python",
   "name": "shad_sdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
